#version 460
#extension GL_KHR_shader_subgroup_arithmetic : require
#extension GL_KHR_shader_subgroup_basic : require
#extension GL_KHR_shader_subgroup_ballot : require

layout(local_size_x = 64, local_size_y = 1, local_size_z = 1) in;

struct InstanceData {
    uint objectIndex;
};

struct ObjectData {
    mat4 modelMatrix;
};

layout(set = 0, binding = 0) readonly buffer Instances { InstanceData instances[]; };

layout(push_constant) uniform constants {
    uint totalInstanceCount;
    float nearD;
    float farD;
    float ratio;
    float sphereFactorX;
    float sphereFactorY;
    float tang;
    vec3 X;
    vec3 Y;
    vec3 Z;
    vec3 camPos;
};

layout(std140, set = 0, binding = 1) readonly buffer Objects { ObjectData objects[]; };
layout(set = 0, binding = 2) buffer VisibleInstances { InstanceData visibleInstances[]; };

layout(set = 0, binding = 3) buffer VisibilityBuffer { uint visibilityBuffer[]; };
layout(set = 0, binding = 4) buffer BlockCounts { uint blockCounts[]; };

layout(set = 0, binding = 5) buffer PrefixSum { uint prefixSum[]; };
layout(set = 0, binding = 6) buffer PartialSums { uint partial_sums[]; };

// radar frustum culling implementation from
// http://www.lighthouse3d.com/tutorials/view-frustum-culling/radar-approach-implementation-ii/
bool sphereInFrustum(vec3 p, float radius) {

    float d;
    float az, ax, ay;
    bool result = true;

    vec3 v = p - camPos;

    az = dot(v, -Z);
    if (az > farD + radius || az < nearD - radius)
        return false;

    if (az > farD - radius || az < nearD + radius)
        result = true;

    ay = dot(v, Y);
    d = sphereFactorY * radius;
    az *= tang;
    if (ay > az + d || ay < -az - d)
        return false;

    if (ay > az - d || ay < -az + d)
        result = true;

    ax = dot(v, X);
    az *= ratio;
    d = sphereFactorX * radius;
    if (ax > az + d || ax < -az - d)
        return false;

    if (ax > az - d || ax < -az + d)
        result = true;

    return (result);
}

uint isVisible(uint index) {
    InstanceData instance = instances[gl_GlobalInvocationID.x];
    mat4 modelMatrix = objects[instance.objectIndex].modelMatrix;
    mat4 modelMatrixT = transpose(modelMatrix);
    float xScale = length(modelMatrixT[0]);
    float yScale = length(modelMatrixT[1]);
    float zScale = length(modelMatrixT[2]);
    vec3 center = vec3(modelMatrix[3]);
    // might not work for radius because objects have different scaling
    // some models might have a much larger or smaller scale than others in order to be reasonably sized
    // this would make the radius too large or too small
    // need to convert scale from model space to world space?
    float radius = max(xScale, max(yScale, zScale)) * 0.5;
    return sphereInFrustum(center, radius) ? 1 : 0;
}

// computeBlockCounts and compact from
// https://web.archive.org/web/20220625140544/http://www.davidespataro.it/cuda-stream-compaction-efficient-implementation/
// https://github.com/knotman90/cuStreamComp/blob/master/src/cuCompactor.cuh
// threadID = gl_LocalInvocationID
// blockID = gl_WorkGroupID
// blockDim = gl_WorkGroupSize = local_size
void computeBlockCounts() {
    uint index = gl_GlobalInvocationID.x;
    if (index < totalInstanceCount) {
        visibilityBuffer[index] = isVisible(index);
        uint BC = subgroupAdd(visibilityBuffer[index]);
        if (gl_LocalInvocationID.x == 0) {
            blockCounts[gl_WorkGroupID.x] = BC;
        }
    }
}

// shared array size must be a constant integer expression
// this allows the shader to work on any GPU with up to a subgroup size of 64 (AMD)
// should be able to set this dynamically with specialization constants
#define maxSubgroupSize 64

shared uint scanData[maxSubgroupSize];
// inclusivePrefixSum from
// https://cachemiss.xyz/blog/parallel-reduce-and-scan-on-the-GPU
void inclusivePrefixSumBlockCounts() {
    uint sum = 0;
    // TODO:
    // possibly run this in a separate vkCmdDispatch call so that it doesn't waste as many threads
    if (gl_GlobalInvocationID.x < gl_WorkGroupSize.x) {
        sum = blockCounts[gl_GlobalInvocationID.x];
    }

    sum = subgroupInclusiveAdd(sum);

    if (gl_SubgroupInvocationID == 0) {
        scanData[gl_SubgroupID] = sum;
    }

    memoryBarrierShared();
    barrier();

    if (gl_SubgroupID == gl_SubgroupSize - 1) {
        uint warpSum = gl_SubgroupInvocationID < gl_NumSubgroups ? scanData[gl_SubgroupInvocationID] : 0;
        warpSum = subgroupInclusiveAdd(warpSum);
        scanData[gl_SubgroupInvocationID] = warpSum;
    }

    memoryBarrierShared();
    barrier();

    uint blockSum = 0;
    if (gl_SubgroupID > 0) {
        blockSum = scanData[gl_SubgroupID - 1];
    }

    sum += blockSum;

    if (gl_GlobalInvocationID.x < gl_WorkGroupSize.x) {
        prefixSum[gl_GlobalInvocationID.x] = sum;
    }
}

// FIXME:
// only run prefix sum once
void inclusivePrefixSumVisibleInstances() {
    uint sum = 0;
    if (gl_GlobalInvocationID.x < totalInstanceCount) {
        sum = visibilityBuffer[gl_GlobalInvocationID.x];
    }

    sum = subgroupInclusiveAdd(sum);

    if (gl_SubgroupInvocationID == 0) {
        scanData[gl_SubgroupID] = sum;
    }

    memoryBarrierShared();
    barrier();

    if (gl_SubgroupID == gl_SubgroupSize - 1) {
        uint warpSum = gl_SubgroupInvocationID < gl_NumSubgroups ? scanData[gl_SubgroupInvocationID] : 0;
        warpSum = subgroupInclusiveAdd(warpSum);
        scanData[gl_SubgroupInvocationID] = warpSum;
    }

    memoryBarrierShared();
    barrier();

    uint blockSum = 0;
    if (gl_SubgroupID > 0) {
        blockSum = scanData[gl_SubgroupID - 1];
    }

    sum += blockSum;

    if (gl_GlobalInvocationID.x < totalInstanceCount) {
        prefixSum[gl_GlobalInvocationID.x] = sum;
    }

    if (gl_LocalInvocationID.x == gl_WorkGroupSize.x - 1) {
        partial_sums[gl_WorkGroupID.x] = sum;
    }

    memoryBarrierShared();
    barrier();

    if (gl_WorkGroupID.x > 0 && gl_GlobalInvocationID.x < totalInstanceCount) {
        sum = 0;
        if (gl_LocalInvocationID.x == 0) {
            sum = partial_sums[gl_WorkGroupID.x - 1];
        }

        memoryBarrierShared();
        // causes a device loss
        // barrier();

        prefixSum[gl_GlobalInvocationID.x] += sum;
    }
}

#define FULL_MASK 0xffffffff
shared uint warpTotals[maxSubgroupSize];
void compact() {
    uint index = gl_GlobalInvocationID.x;
    if (index < totalInstanceCount) {
        uint pred = visibilityBuffer[index];
        uint w_i = gl_LocalInvocationID.x / gl_SubgroupSize;
        uint w_l = index % gl_SubgroupSize;

        uint t_m = FULL_MASK >> (gl_SubgroupSize - w_l);
        uvec4 b = subgroupBallot(pred != 0) & t_m;
        uint t_u = subgroupBallotExclusiveBitCount(b);

        if (w_l == gl_SubgroupSize - 1) {
            warpTotals[w_i] = t_u + pred;
        }

        memoryBarrierShared();

        uint numWarps = gl_WorkGroupSize.x / gl_SubgroupSize;
        uint numWarpsMask = FULL_MASK >> (gl_SubgroupSize - numWarps);
        if (w_i == 0 && w_l < numWarps) {
            uint w_i_u = 0;
            for (uint j = 0; j <= log2(gl_SubgroupSize); ++j) {
                uvec4 b_j = subgroupBallot((warpTotals[w_l] & (1 << j)) != 0);
                w_i_u += (subgroupBallotExclusiveBitCount(b_j & t_m)) << j;
            }
            warpTotals[w_l] = w_i_u;
        }

        memoryBarrierShared();

        if (pred == 1) {
            visibleInstances[t_u + warpTotals[w_i] + prefixSum[gl_WorkGroupID.x]] = instances[index];
        }
    }
}

void main() {
    computeBlockCounts();
    inclusivePrefixSumBlockCounts();
    compact();
    memoryBarrierShared();
    barrier();
    inclusivePrefixSumVisibleInstances();
}
